{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = ['''In recent times, the emergence of advanced Large Language models (LLMs) like ChatGPT and Bard has remarkably enhanced the quality of artificially generated text, blurring the lines between synthetic and human-written content. However, this progress has some significant concerns across ethical, moral, legal, social, and economic realms in various industries. To overcome these concerns, our study introduces a method designed to detect the synthetically generated text (SGT) and human-written text (HWT).\n",
    "\n",
    "To create this Machine Learning model, first we require both synthetic and manually written text data for comparison purposes. We are going to include dataset from Kaggle (JONATHAN HERRERA Augmented data for LLM - Detect AI Generated Text). The data set is in raw form which contains two columns text and label, in label 1 indicates AI generated and 0 indicates human written. We need to clean the dataset by filling missing values.\n",
    "\n",
    "Once our dataset is ready, we will use NLP-based feature extraction to compare the features of the synthetic and human-generated data, This work is doing before training our Machine Learning model. When working with datasets for NLP (Natural Language Processing) tasks, it is very important to carry out feature engineering. This involves using similar techniques for datasets to gain a better understanding of their patterns and characteristics. We have to create basic NLP-related features like word count, punctuation usage, title presence, and the way characters are written (like uppercase or lowercase). TD-IDF-related features, N-gram features, topic modeling features, readability scores, named entity recognition (NER) counts, and text error length features. To determine the best set of features, we use principal component analysis (PCA). These features will be useful in classifying the datasets. To find an optimal set of features, principal component analysis is used.\n",
    "\n",
    "In order to differentiate between HWT (Hand written text) and SGT (Synthetic generated text), we need to take help from Machine Learning algorithms. We need to employed classifiers algorithms like Random Forest (RF), Support Vector Machine (SVM), and XGBoost (XGB) to perform the classification for identifying either human-written or ChatGPT generated text based on the collected handcrafted features. Our models were trained, fine-tuned, and tested using the dataset. \n",
    "\n",
    "We used Precision, Recall, and F1 scores as metrics to evaluate and compare the performance our model. The whole model is deployed with the web interface by using Django Framework.''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In recent times, the emergence of advanced Lar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  In recent times, the emergence of advanced Lar..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.read_csv('input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>gunning_fog_score</th>\n",
       "      <th>coleman_liau_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>linsear_write_score</th>\n",
       "      <th>spache_score</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>error_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In recent times , the emergence of advanced La...</td>\n",
       "      <td>in recent times the emergence of advanced larg...</td>\n",
       "      <td>2479</td>\n",
       "      <td>383</td>\n",
       "      <td>0.154498</td>\n",
       "      <td>87</td>\n",
       "      <td>126</td>\n",
       "      <td>49</td>\n",
       "      <td>124</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>153.8</td>\n",
       "      <td>-325.74</td>\n",
       "      <td>158.84</td>\n",
       "      <td>15.98</td>\n",
       "      <td>28.41</td>\n",
       "      <td>195.9</td>\n",
       "      <td>71.0</td>\n",
       "      <td>57.31</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  In recent times , the emergence of advanced La...   \n",
       "\n",
       "                                        cleaned_text  char_count  word_count  \\\n",
       "0  in recent times the emergence of advanced larg...        2479         383   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_count  title_word_count  \\\n",
       "0      0.154498                 87               126                49   \n",
       "\n",
       "   noun_count  adv_count  ...  flesch_kincaid_score  flesch_score  \\\n",
       "0         124          8  ...                 153.8       -325.74   \n",
       "\n",
       "   gunning_fog_score  coleman_liau_score  dale_chall_score  ari_score  \\\n",
       "0             158.84               15.98             28.41      195.9   \n",
       "\n",
       "   linsear_write_score  spache_score  ner_count  error_length  \n",
       "0                 71.0         57.31         30            75  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('svm_model2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = tf.drop(['text', 'cleaned_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>...</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>gunning_fog_score</th>\n",
       "      <th>coleman_liau_score</th>\n",
       "      <th>dale_chall_score</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>linsear_write_score</th>\n",
       "      <th>spache_score</th>\n",
       "      <th>ner_count</th>\n",
       "      <th>error_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2479</td>\n",
       "      <td>383</td>\n",
       "      <td>0.154498</td>\n",
       "      <td>87</td>\n",
       "      <td>126</td>\n",
       "      <td>49</td>\n",
       "      <td>124</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>153.8</td>\n",
       "      <td>-325.74</td>\n",
       "      <td>158.84</td>\n",
       "      <td>15.98</td>\n",
       "      <td>28.41</td>\n",
       "      <td>195.9</td>\n",
       "      <td>71.0</td>\n",
       "      <td>57.31</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  upper_case_count  \\\n",
       "0        2479         383      0.154498                 87               126   \n",
       "\n",
       "   title_word_count  noun_count  adv_count  verb_count  adj_count  ...  \\\n",
       "0                49         124          8          86         43  ...   \n",
       "\n",
       "   flesch_kincaid_score  flesch_score  gunning_fog_score  coleman_liau_score  \\\n",
       "0                 153.8       -325.74             158.84               15.98   \n",
       "\n",
       "   dale_chall_score  ari_score  linsear_write_score  spache_score  ner_count  \\\n",
       "0             28.41      195.9                 71.0         57.31         30   \n",
       "\n",
       "   error_length  \n",
       "0            75  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.head()\n",
    "# print(\"Shape of new_text_features:\", new_X.shape)\n",
    "# print(\"Data types of new_text_features:\", new_X.dtypes)\n",
    "# new_X.drop(new_X.columns[-2:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is predicted to be AI-generated.\n"
     ]
    }
   ],
   "source": [
    "# prediction_proba = model.predict_proba(new_X)\n",
    "prediction = model.predict(new_X)\n",
    "\n",
    "# print(\"Prediction Probabilities:\", prediction_proba)\n",
    "\n",
    "# Display the result\n",
    "if prediction == 0:\n",
    "    print(\"The text is predicted to be human-generated.\")\n",
    "else:\n",
    "    print(\"The text is predicted to be AI-generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
